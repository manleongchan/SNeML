\relax 
\providecommand\hyper@newdestlabel[2]{}
\AC@reset@newl@bel
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{abbott2016observation}
\citation{abbott2016gw151226,abbott2017gw170608,abbott2017gw170814}
\citation{abbott2017gw170817,abbott2017gravitational,abbott2017multi}
\citation{abbott2017multi}
\citation{aso2013interferometer,somiya2012detector,abbott2018prospects}
\citation{aasi2015advanced}
\citation{acernese2014advanced}
\citation{aso2013interferometer,gossan2016observing,abbott2016first}
\citation{sato1987analysis}
\citation{baron1990effect,bethe1990supernova}
\citation{o2011black}
\citation{bethe1985revival,bethe1990supernova}
\citation{janka2012explosion,kotake2012core,mezzacappa2014two}
\citation{takiwaki2016three,summa2018rotation}
\citation{bruenn2016development}
\citation{bethe1985revival,janka2007theory}
\citation{couch2015role}
\citation{blondin2003stability}
\citation{leblanc1970numerical,burrows2007simulations,takiwaki2009special,moiseenko2006magnetorotational,mosta2014magnetorotational}
\citation{woosley2006progenitor,yoon2005evolution,de2013rotation}
\citation{ott2009gravitational,kotake2013multiple,kotake2009stochastic}
\citation{heng2009rotating,rover2009bayesian,powell2015classification,powell2017classification,suvorova2019reconstructing}
\citation{rover2009bayesian}
\citation{logue2012inferring}
\citation{engels2014multivariate}
\citation{summerscales2008maximum}
\citation{gursel1989near}
\citation{rakhmanov2006rank,hayama2007coherent}
\newlabel{FirstPage}{{}{1}{}{Doc-Start}{}}
\newacro{GW}[GW]{gravitational wave}
\newacro{BNS}[BNS]{binary neutron star}
\newacro{BBH}[BBH]{binary black hole}
\newacro{NSBH}[NSBH]{neutron star black hole}
\newacro{EM}[EM]{electromagnetic}
\newacro{CBC}[CBC]{compact binary coalescence}
\newacro{CNN}[CNN]{Convolutional neural network}
\newacro{CCSN}[CCSN]{core collapse supernova}
\newacroplural{CCSN}[CCSNe]{core collapse supernovae}
\newacro{ROC}[ROC]{receiver operator characteristic}
\newacro{TAP}[TAP]{true alarm probability}
\newacro{FAP}[FAP]{false alarm probability}
\newacro{aLIGO}[aLIGO]{advanced LIGO}
\newacro{AdVirgo}[AdVirgo]{advanced VIRGO}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section*.1}}
\AC@undonewlabel{acro:GW}
\newlabel{acro:GW}{{I}{1}{}{section*.2}{}}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\acronymused{GW}
\AC@undonewlabel{acro:CCSN}
\newlabel{acro:CCSN}{{I}{1}{}{section*.3}{}}
\acronymused{CCSN}
\AC@undonewlabel{acro:aLIGO}
\newlabel{acro:aLIGO}{{I}{1}{}{section*.4}{}}
\acronymused{aLIGO}
\AC@undonewlabel{acro:AdVirgo}
\newlabel{acro:AdVirgo}{{I}{1}{}{section*.5}{}}
\acronymused{AdVirgo}
\acronymused{CCSN}
\acronymused{CCSN}
\acronymused{CCSN}
\acronymused{GW}
\acronymused{CCSN}
\acronymused{GW}
\acronymused{CCSN}
\acronymused{CCSN}
\acronymused{GW}
\acronymused{GW}
\acronymused{CCSN}
\citation{krizhevsky2012imagenet,NIPS2014_5423,simonyan2014very,chen2014semantic,zeiler2014visualizing,szegedy2015going}
\citation{kononenko2001machine}
\citation{redmon2016you}
\citation{he2016deep,krizhevsky2012imagenet,zhang2016colorful,karpathy2015deep}
\citation{lample2016neural}
\citation{mukund2017transient,zevin2017gravity,george2017deep,gabbard2018matching}
\citation{george2018deep,astone2018new}
\citation{goodfellow2016deep}
\citation{miller2015prospects,LIGOW}
\citation{o2015introduction}
\citation{o2015introduction}
\citation{lecun1988theoretical}
\citation{abadi2016tensorflow}
\acronymused{CCSN}
\acronymused{CCSN}
\acronymused{CCSN}
\acronymused{GW}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{I}{2}{}{section*.6}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{GW}
\acronymused{CCSN}
\acronymused{aLIGO}
\acronymused{AdVirgo}
\acronymused{AdVirgo}
\acronymused{aLIGO}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {section}{\numberline {II}Convolutional Neural network}{2}{section*.7}}
\newlabel{sec:CNN}{{II}{2}{}{section*.7}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\newlabel{eq:cce}{{1}{2}{}{equation.2.1}{}}
\citation{richers2017equation}
\citation{ott2009gravitational,murphy2009model,ott2013general}
\citation{ott2009gravitational}
\citation{murphy2009model}
\citation{ott2013general}
\citation{ott2013general}
\citation{ott2013general}
\citation{richers2017equation}
\citation{ott2013general}
\citation{ott2013general}
\citation{richers2017equation}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces The architecture of the \ac {CNN}}}{3}{table.1}}
\acronymused{CNN}
\newlabel{table:architecture}{{I}{3}{The architecture of the \ac {CNN}}{table.1}{}}
\acronymused{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An illustration of the architecture of the \ac {CNN} used in this paper for the detection and classification of \ac {CCSN} signals in noisy data. The \ac {CNN} consists of $8$ convolutional layers, $3$ max-pooling layers and $3$ fully connected layer including the output layer. The input layer takes the simulated time series of the detectors as input, feeding through the \ac {CNN}. The \ac {CNN} will output three probabilities at the last layer. The numbers above or below each layer indicate the kernal size of the layer. For example, the first convolutional layer has $9$ filters, each of which is $1$ by $64$ in size. The elements in the figure are not to scale. }}{3}{figure.1}}
\acronymused{CNN}
\acronymused{CCSN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\newlabel{fig:CNN}{{1}{3}{An illustration of the architecture of the \ac {CNN} used in this paper for the detection and classification of \ac {CCSN} signals in noisy data. The \ac {CNN} consists of $8$ convolutional layers, $3$ max-pooling layers and $3$ fully connected layer including the output layer. The input layer takes the simulated time series of the detectors as input, feeding through the \ac {CNN}. The \ac {CNN} will output three probabilities at the last layer. The numbers above or below each layer indicate the kernal size of the layer. For example, the first convolutional layer has $9$ filters, each of which is $1$ by $64$ in size. The elements in the figure are not to scale}{figure.1}{}}
\acronymused{CNN}
\@writefile{toc}{\contentsline {section}{\numberline {III}Data}{3}{section*.8}}
\newlabel{sec:spwf}{{III}{3}{}{section*.8}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CCSN}
\newlabel{eq:ht}{{2}{3}{}{equation.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of simulated waveforms from both mechanisms used in the work. The top panel shows an example waveform of the neutrino-driven mechanism from\cite  {ott2013general}. The progenitor is $27M_\odot $ with neutrino heating rate $f_\text  {heat}$ equal to 1.15 in \cite  {ott2013general}. The $h+$ and the $h\times $ polarisations are shown in blue and red respectively. The bottom panel shows a waveform from the magnetorotational mechanism. The simulation is done assuming a progenitor of $12M_\odot $ with maximum initial rotation rate equal to $12$ rad/s and a measure of the degree of differential rotation equal to $300$km in Eq.5 in\cite  {richers2017equation}. Only the $h+$ polarisation is shown because the simulation is axis-symmetric and described by only one polarisation. Both sources are assumed to be at $10$ kpc from earth. }}{4}{figure.2}}
\newlabel{fig:waveforms}{{2}{4}{Examples of simulated waveforms from both mechanisms used in the work. The top panel shows an example waveform of the neutrino-driven mechanism from\cite {ott2013general}. The progenitor is $27M_\odot $ with neutrino heating rate $f_\text {heat}$ equal to 1.15 in \cite {ott2013general}. The $h+$ and the $h\times $ polarisations are shown in blue and red respectively. The bottom panel shows a waveform from the magnetorotational mechanism. The simulation is done assuming a progenitor of $12M_\odot $ with maximum initial rotation rate equal to $12$ rad/s and a measure of the degree of differential rotation equal to $300$km in Eq.5 in\cite {richers2017equation}. Only the $h+$ polarisation is shown because the simulation is axis-symmetric and described by only one polarisation. Both sources are assumed to be at $10$ kpc from earth}{figure.2}{}}
\acronymused{GW}
\newlabel{eq:sap}{{3}{4}{}{equation.3.3}{}}
\acronymused{GW}
\acronymused{CNN}
\newlabel{eq:ap}{{4}{4}{}{equation.3.4}{}}
\newlabel{eq:tdetector}{{5}{4}{}{equation.3.5}{}}
\acronymused{GW}
\newlabel{eq:ht2}{{6}{4}{}{equation.3.6}{}}
\acronymused{CNN}
\newlabel{eq:noise}{{8}{4}{}{equation.3.8}{}}
\acronymused{CNN}
\acronymused{CNN}
\citation{karachentsev2004catalog,belokurov2007cats}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Representative example of the simulated time series used to train/validate/test the \ac {CNN}. The blue shows a whitened time series with a signal buried in Gaussian noise of unit variance. The red shows the same signal free of noise and whitened. The signal is the same as the one shown in the top panel in Figure \ref  {fig:waveforms} but with antenna pattern applied. }}{5}{figure.3}}
\acronymused{CNN}
\newlabel{fig:sample}{{3}{5}{Representative example of the simulated time series used to train/validate/test the \ac {CNN}. The blue shows a whitened time series with a signal buried in Gaussian noise of unit variance. The red shows the same signal free of noise and whitened. The signal is the same as the one shown in the top panel in Figure \ref {fig:waveforms} but with antenna pattern applied}{figure.3}{}}
\newlabel{eq:finaldata}{{9}{5}{}{equation.3.9}{}}
\acronymused{GW}
\acronymused{GW}
\acronymused{CNN}
\acronymused{GW}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Result and discussion}{5}{section*.9}}
\newlabel{sec:result}{{IV}{5}{}{section*.9}{}}
\acronymused{CNN}
\AC@undonewlabel{acro:ROC}
\newlabel{acro:ROC}{{IV}{5}{}{section*.10}{}}
\acronymused{ROC}
\acronymused{ROC}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Detector networks}}{5}{table.2}}
\newlabel{table:network}{{II}{5}{Detector networks}{table.2}{}}
\acronymused{aLIGO}
\acronymused{aLIGO}
\acronymused{AdVirgo}
\acronymused{AdVirgo}
\AC@undonewlabel{acro:TAP}
\newlabel{acro:TAP}{{IV}{5}{}{section*.11}{}}
\acronymused{TAP}
\AC@undonewlabel{acro:FAP}
\newlabel{acro:FAP}{{IV}{5}{}{section*.12}{}}
\acronymused{FAP}
\acronymused{ROC}
\acronymused{ROC}
\acronymused{FAP}
\acronymused{ROC}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{ROC}
\acronymused{GW}
\acronymused{CNN}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{CNN}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{CNN}
\acronymused{FAP}
\acronymused{CNN}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{FAP}
\acronymused{CNN}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{GW}
\acronymused{CCSN}
\acronymused{CNN}
\newlabel{fig:ROClog1}{{4(a)}{6}{Subfigure 4(a)}{subfigure.4.1}{}}
\newlabel{sub@fig:ROClog1}{{(a)}{6}{Subfigure 4(a)\relax }{subfigure.4.1}{}}
\newlabel{fig:ROClog2}{{4(b)}{6}{Subfigure 4(b)}{subfigure.4.2}{}}
\newlabel{sub@fig:ROClog2}{{(b)}{6}{Subfigure 4(b)\relax }{subfigure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces ROC curves showing the classification performance of the \ac {CNN} for \ac {CCSN} signals of different explosion mechanism at three distances. For the distances shown in the both panels, the solid lines in both panels are for signals from the magnetorotational mechanism, while the dashed lines are for the neutrino-driven mechanism. The left panel shows the result for the network of HLVK, while the panel on the right shows that for H+L+VK. }}{6}{figure.4}}
\acronymused{CNN}
\acronymused{CCSN}
\newlabel{fig:ROClog}{{4}{6}{ROC curves showing the classification performance of the \ac {CNN} for \ac {CCSN} signals of different explosion mechanism at three distances. For the distances shown in the both panels, the solid lines in both panels are for signals from the magnetorotational mechanism, while the dashed lines are for the neutrino-driven mechanism. The left panel shows the result for the network of HLVK, while the panel on the right shows that for H+L+VK}{figure.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}{figure.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}{figure.4}}
\newlabel{fig:eff1}{{5(a)}{6}{Subfigure 5(a)}{subfigure.5.1}{}}
\newlabel{sub@fig:eff1}{{(a)}{6}{Subfigure 5(a)\relax }{subfigure.5.1}{}}
\newlabel{fig:eff2}{{5(b)}{6}{Subfigure 5(b)}{subfigure.5.2}{}}
\newlabel{sub@fig:eff2}{{(b)}{6}{Subfigure 5(b)\relax }{subfigure.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Efficiency curves showing the classification ability of the \ac {CNN} as a function of distance for both mechanisms and networks. In both panels, the solid lines show the results for the magnetorotational mechanism, while the dashed lines for the neutrino-driven mechanism. The left panel shows the result for the network of HLVK, while the panel on the right shows that for H+L+VK. Three \acp {FAP} are chosen, i.e.: blue for \ac {FAP} $=0.1$, green for \ac {FAP} $=0.01$, red for \ac {FAP} $=0.001$. }}{6}{figure.5}}
\acronymused{CNN}
\acronymused{FAP}
\acronymused{FAP}
\acronymused{FAP}
\acronymused{FAP}
\newlabel{fig:eff}{{5}{6}{Efficiency curves showing the classification ability of the \ac {CNN} as a function of distance for both mechanisms and networks. In both panels, the solid lines show the results for the magnetorotational mechanism, while the dashed lines for the neutrino-driven mechanism. The left panel shows the result for the network of HLVK, while the panel on the right shows that for H+L+VK. Three \acp {FAP} are chosen, i.e.: blue for \ac {FAP} $=0.1$, green for \ac {FAP} $=0.01$, red for \ac {FAP} $=0.001$}{figure.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}{figure.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}{figure.5}}
\acronymused{CNN}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{GW}
\acronymused{CCSN}
\acronymused{CNN}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{TAP}
\acronymused{CNN}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{FAP}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{6}{section*.13}}
\newlabel{sec:conclusion}{{V}{6}{}{section*.13}{}}
\acronymused{CNN}
\acronymused{GW}
\acronymused{CNN}
\acronymused{GW}
\bibdata{main}
\bibcite{abbott2016observation}{{1}{}{{}}{{}}}
\bibcite{abbott2016gw151226}{{2}{}{{}}{{}}}
\bibcite{abbott2017gw170608}{{3}{}{{}}{{}}}
\bibcite{abbott2017gw170814}{{4}{}{{}}{{}}}
\bibcite{abbott2017gw170817}{{5}{}{{}}{{}}}
\bibcite{abbott2017gravitational}{{6}{}{{}}{{}}}
\bibcite{abbott2017multi}{{7}{}{{}}{{}}}
\bibcite{aso2013interferometer}{{8}{}{{}}{{}}}
\bibcite{somiya2012detector}{{9}{}{{}}{{}}}
\bibcite{abbott2018prospects}{{10}{}{{}}{{}}}
\bibcite{aasi2015advanced}{{11}{}{{}}{{}}}
\newlabel{fig:ROCfixed1}{{6(a)}{7}{Subfigure 6(a)}{subfigure.6.1}{}}
\newlabel{sub@fig:ROCfixed1}{{(a)}{7}{Subfigure 6(a)\relax }{subfigure.6.1}{}}
\newlabel{fig:ROCfixed2}{{6(b)}{7}{Subfigure 6(b)}{subfigure.6.2}{}}
\newlabel{sub@fig:ROCfixed2}{{(b)}{7}{Subfigure 6(b)\relax }{subfigure.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Efficiency curves showing the ability of the \ac {CNN} in distinguishing input data with a fixed decision threshold, and their corresponding \acp {FAP}. The left panel shows the results for the neutrino-driven mechanism, and the right shows that for the magnetorotational mechanism. In both panels, the solid lines show the \acp {TAP} and \acp {FAP} for H+L+VK, and the dashed lines show those for HLVK. }}{7}{figure.6}}
\acronymused{CNN}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{FAP}
\newlabel{fig:ROCfixed}{{6}{7}{Efficiency curves showing the ability of the \ac {CNN} in distinguishing input data with a fixed decision threshold, and their corresponding \acp {FAP}. The left panel shows the results for the neutrino-driven mechanism, and the right shows that for the magnetorotational mechanism. In both panels, the solid lines show the \acp {TAP} and \acp {FAP} for H+L+VK, and the dashed lines show those for HLVK}{figure.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{7}{figure.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{7}{figure.6}}
\acronymused{CNN}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{CNN}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{CCSN}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{FAP}
\acronymused{TAP}
\acronymused{FAP}
\acronymused{TAP}
\@writefile{toc}{\contentsline {section}{\numberline {}ACKNOWLEDGEMENTS}{7}{section*.14}}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{7}{section*.15}}
\bibcite{acernese2014advanced}{{12}{}{{}}{{}}}
\bibcite{gossan2016observing}{{13}{}{{}}{{}}}
\bibcite{abbott2016first}{{14}{}{{}}{{}}}
\bibcite{sato1987analysis}{{15}{}{{}}{{}}}
\bibcite{baron1990effect}{{16}{}{{}}{{}}}
\bibcite{bethe1990supernova}{{17}{}{{}}{{}}}
\bibcite{o2011black}{{18}{}{{}}{{}}}
\bibcite{bethe1985revival}{{19}{}{{}}{{}}}
\bibcite{janka2012explosion}{{20}{}{{}}{{}}}
\bibcite{kotake2012core}{{21}{}{{}}{{}}}
\bibcite{mezzacappa2014two}{{22}{}{{}}{{}}}
\bibcite{takiwaki2016three}{{23}{}{{}}{{}}}
\bibcite{summa2018rotation}{{24}{}{{}}{{}}}
\bibcite{bruenn2016development}{{25}{}{{}}{{}}}
\bibcite{janka2007theory}{{26}{}{{}}{{}}}
\bibcite{couch2015role}{{27}{}{{}}{{}}}
\bibcite{blondin2003stability}{{28}{}{{}}{{}}}
\bibcite{leblanc1970numerical}{{29}{}{{}}{{}}}
\bibcite{burrows2007simulations}{{30}{}{{}}{{}}}
\bibcite{takiwaki2009special}{{31}{}{{}}{{}}}
\bibcite{moiseenko2006magnetorotational}{{32}{}{{}}{{}}}
\bibcite{mosta2014magnetorotational}{{33}{}{{}}{{}}}
\bibcite{woosley2006progenitor}{{34}{}{{}}{{}}}
\bibcite{yoon2005evolution}{{35}{}{{}}{{}}}
\bibcite{de2013rotation}{{36}{}{{}}{{}}}
\bibcite{ott2009gravitational}{{37}{}{{}}{{}}}
\bibcite{kotake2013multiple}{{38}{}{{}}{{}}}
\bibcite{kotake2009stochastic}{{39}{}{{}}{{}}}
\bibcite{heng2009rotating}{{40}{}{{}}{{}}}
\bibcite{rover2009bayesian}{{41}{}{{}}{{}}}
\bibcite{powell2015classification}{{42}{}{{}}{{}}}
\bibcite{powell2017classification}{{43}{}{{}}{{}}}
\bibcite{suvorova2019reconstructing}{{44}{}{{}}{{}}}
\bibcite{logue2012inferring}{{45}{}{{}}{{}}}
\bibcite{engels2014multivariate}{{46}{}{{}}{{}}}
\bibcite{summerscales2008maximum}{{47}{}{{}}{{}}}
\bibcite{gursel1989near}{{48}{}{{}}{{}}}
\bibcite{rakhmanov2006rank}{{49}{}{{}}{{}}}
\bibcite{hayama2007coherent}{{50}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{51}{}{{}}{{}}}
\bibcite{NIPS2014_5423}{{52}{}{{}}{{}}}
\bibcite{simonyan2014very}{{53}{}{{}}{{}}}
\bibcite{chen2014semantic}{{54}{}{{}}{{}}}
\bibcite{zeiler2014visualizing}{{55}{}{{}}{{}}}
\bibcite{szegedy2015going}{{56}{}{{}}{{}}}
\bibcite{kononenko2001machine}{{57}{}{{}}{{}}}
\bibcite{redmon2016you}{{58}{}{{}}{{}}}
\bibcite{he2016deep}{{59}{}{{}}{{}}}
\bibcite{zhang2016colorful}{{60}{}{{}}{{}}}
\bibcite{karpathy2015deep}{{61}{}{{}}{{}}}
\bibcite{lample2016neural}{{62}{}{{}}{{}}}
\bibcite{mukund2017transient}{{63}{}{{}}{{}}}
\bibcite{zevin2017gravity}{{64}{}{{}}{{}}}
\bibcite{george2017deep}{{65}{}{{}}{{}}}
\bibcite{gabbard2018matching}{{66}{}{{}}{{}}}
\bibcite{george2018deep}{{67}{}{{}}{{}}}
\bibcite{astone2018new}{{68}{}{{}}{{}}}
\bibcite{goodfellow2016deep}{{69}{}{{}}{{}}}
\bibcite{miller2015prospects}{{70}{}{{}}{{}}}
\bibcite{LIGOW}{{71}{}{{}}{{}}}
\bibcite{o2015introduction}{{72}{}{{}}{{}}}
\bibcite{lecun1988theoretical}{{73}{}{{}}{{}}}
\bibcite{abadi2016tensorflow}{{74}{}{{}}{{}}}
\bibcite{richers2017equation}{{75}{}{{}}{{}}}
\bibcite{murphy2009model}{{76}{}{{}}{{}}}
\bibcite{ott2013general}{{77}{}{{}}{{}}}
\bibcite{karachentsev2004catalog}{{78}{}{{}}{{}}}
\bibcite{belokurov2007cats}{{79}{}{{}}{{}}}
\global \chardef \firstnote@num\z@ \relax 
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\bibstyle{unsrt3}
\newlabel{LastPage}{{}{10}{}{page.10}{}}
\newlabel{LastBibItem}{{79}{10}{}{section*.15}{}}
