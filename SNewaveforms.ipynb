{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This code is for reading simulated SNe waveforms\"\"\"\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Qt4Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate, interpolate, signal, optimize, stats\n",
    "import cPickle as pickle\n",
    "\n",
    "import lal\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, BatchNormalization, Flatten\n",
    "from keras.optimizers import Nadam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "import pyfftw\n",
    "np.set_printoptions(edgeitems=30, linewidth=160)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.2167168764\n",
      "360.8339166439981\n"
     ]
    }
   ],
   "source": [
    "SNR_= np.array(waveformfile[u'reduced_data'][u'SNR(aLIGOfrom10kpc)'])\n",
    "i = 3\n",
    "print(SNR_[i])\n",
    "print(SNR[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: [u'reduced_data', u'waveforms', u'yeofrho']\n"
     ]
    }
   ],
   "source": [
    "filename = './Data/GWdatabase.h5'\n",
    "waveformfile = h5py.File(filename, 'r')\n",
    "\n",
    "# List all groups\n",
    "print(\"Keys: %s\" % waveformfile.keys())\n",
    "\n",
    "reduced_data = waveformfile.keys()[0]\n",
    "waveformfilekey = waveformfile.keys()[1]\n",
    "yeofrho = waveformfile.keys()[2]\n",
    "\n",
    "waveformfamily = []\n",
    "waveformfamily_keys = []\n",
    "\n",
    "for i, key in enumerate(waveformfile[waveformfilekey].keys()):\n",
    "    waveformfamily.append(key)\n",
    "    if i == 0:\n",
    "        for j, _ in enumerate(waveformfile[waveformfilekey][waveformfamily[i]].keys()):\n",
    "            waveformfamily_keys.append(waveformfile[waveformfilekey][waveformfamily[i]].keys()[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27818, 94, 13188, 12)\n"
     ]
    }
   ],
   "source": [
    "PctMe = lal.PC_SI \n",
    "Dist = 10.0 * 1e3 * PctMe * 1e2 #(centimeters)\n",
    "findmax = 0\n",
    "k = 0 \n",
    "findmin = 1e10\n",
    "kmin = 0\n",
    "length = np.zeros(len(waveformfamily))\n",
    "#waveformfamily = [waveformfamily[0]]\n",
    "no_waves_considered = 100\n",
    "for i in range(len(waveformfamily[0:no_waves_considered])):\n",
    "    waveformnumber = i\n",
    "\n",
    "    ts = np.array(waveformfile[waveformfilekey][waveformfamily[waveformnumber]][u't-tb(s)']) \n",
    "    #waves = np.array(waveforms[waveformkey][waveformfamily[waveformnumber]][u'strain*dist(cm)']) / Dist \n",
    "    if findmax < len(ts):\n",
    "        findmax = len(ts)\n",
    "        k = i\n",
    "    if findmin > len(ts):\n",
    "        findmin = len(ts)\n",
    "        kmin = i\n",
    "    length[i] = len(ts)   \n",
    "    #plt.plot(ts, waves)\n",
    "#plt.show()\n",
    "print(findmax, k, findmin, kmin)\n",
    "findmax += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6566702, 0.0010305176, 0.0010457764)\n",
      "108507\n"
     ]
    }
   ],
   "source": [
    "ts = np.array(waveformfile[waveformfilekey][waveformfamily[197]][u't-tb(s)']) \n",
    "print(ts[-1], ts[2], ts[3])\n",
    "print(len(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(length)), length)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padandextractwave(waveformfile, waveformfilekey, waveformfamily, strainkey, wavemaxlength, FDish, no_waves_considered):\n",
    "    noofwaves = len(waveformfamily[0:no_waves_considered])\n",
    "    extractedwaveforms = np.array([np.zeros(wavemaxlength / 8) for i in range(noofwaves)])\n",
    "    R = 8\n",
    "    for i, whichsimulation in enumerate(waveformfamily[0:no_waves_considered]):\n",
    "        \n",
    "        wave = np.array(waveformfile[waveformfilekey][whichsimulation][strainkey]) / FDish\n",
    "        wavelength = len(wave)\n",
    "        temporary = np.pad(wave, (0, wavemaxlength - wavelength), 'constant', constant_values = 0)\n",
    "        extractedwaveforms[i] = signal.decimate(temporary, R, ftype='iir')\n",
    "        \n",
    "    return extractedwaveforms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sr = 65535\n",
    "\n",
    "length[k] = 0\n",
    "#findmax = np.amax(length).astype(int) + 1\n",
    "findmax = 108512#len(SNewaves[0]) +1\n",
    "Tobs = findmax / 65535.0\n",
    "SNewaves = padandextractwave(waveformfile, waveformfilekey, waveformfamily, u'strain*dist(cm)', findmax, Dist, no_waves_considered)\n",
    "\n",
    "\n",
    "New_sr = (len(SNewaves[0]) - 1) / Tobs\n",
    "New_dt = 1.0 / New_sr\n",
    "\n",
    "\n",
    "ts = np.arange(len(SNewaves[0])) * New_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6559090652298774, 1.6557869840543222)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SNewaves[0]) * New_dt, ts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Part of The Code Reads The Noise Curve Files For The Selected Detectors  \n",
    "#help(lal.ArrivalTimeDiff)\n",
    "def ASDtxt(x):\n",
    "    return {\n",
    "        'LET':'./ASD/ET_D.txt',\n",
    "        'LCE':'./ASD/CE.txt',\n",
    "        'H1': './ASD/ligoII_NS.txt',\n",
    "        'L1': './ASD/ligoII_NS.txt',\n",
    "        'V1': './ASD/virgoII.txt',\n",
    "        'I2': './ASD/ligoII_NS.txt',\n",
    "        'KAGRA': './ASD/ligoII_NS.txt',\n",
    "        'ET_1': './ASD/ET_D.txt',\n",
    "        'ET_2': './ASD/ET_D.txt',\n",
    "        'ET_3': './ASD/ET_D.txt',\n",
    "        'A2': './ASD/ligoII_NS.txt',\n",
    "        'A2.5': './ASD/ligoII_NS.txt',\n",
    "    }[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the noise curves.\n",
    "def readnos(detector, f_points):\n",
    "    nos_file = ASDtxt(detector)\n",
    "    f_str = []\n",
    "    ASD_str = []\n",
    "    file = open(nos_file, 'r')\n",
    "    readFile = file.readlines()\n",
    "    file.close()\n",
    "    f = []\n",
    "    ASD = []\n",
    "    \n",
    "    for line in readFile:\n",
    "        p = line.split()\n",
    "        f_str.append(float(p[0]))\n",
    "        ASD_str.append(float(p[1]))\n",
    "    f = np.log10(np.array(f_str))\n",
    "    ASD = np.log10(np.array(ASD_str))\n",
    "    nosinterpolate = interpolate.splrep(f, ASD, w=1.0*np.ones(len(ASD)), s=0)\n",
    "    \n",
    "    nos = interpolate.splev(np.log10(f_points), nosinterpolate, der = 0, ext = 3)\n",
    "    nos = 10**nos\n",
    "    \n",
    "    return nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisegenerator(Tobs, det, SR, df, dt):\n",
    "    Ns = Tobs * SR\n",
    "    Nf = int(np.ceil(Ns /2) + 1)\n",
    "    fs = np.arange(Nf) * df\n",
    "    ASD = readnos('H1', fs)\n",
    "    Amp = np.sqrt(Tobs) * ASD\n",
    "    \n",
    "    real_nos = Amp * np.random.normal(0.0, 1.0, Nf)\n",
    "    img_nos = Amp * np.random.normal(0.0, 1.0, Nf)\n",
    "    \n",
    "    nos = real_nos + 1j * img_nos\n",
    "    \n",
    "    idx_1 = int(20 // df)\n",
    "    nos[0:idx_1] = 0\n",
    "    \n",
    "    \n",
    "    fftinput = pyfftw.empty_aligned(len(nos), dtype='complex128')\n",
    "    \n",
    "    fft_object = pyfftw.builders.irfft(fftinput)\n",
    "\n",
    "    nos_realization = fft_object(nos) * df\n",
    "\n",
    "    return nos_realization, fs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(seed, ts, Sr, Det, SNewaves, N_rz, multiplication):\n",
    "    np.random.seed(seed)\n",
    "    data = np.array([np.zeros_like(ts) for i in range(N_rz)])\n",
    "    \n",
    "    SNR = np.zeros(N_rz)\n",
    "    Ns = len(ts)\n",
    "    Nf = int(np.ceil(Ns /2) + 1)\n",
    "    Tobs = ts[-1]\n",
    "    df = 1.0/Tobs\n",
    "    \n",
    "    fs = np.arange(Nf) * df\n",
    "    ASD = readnos(Det, fs)\n",
    "    \n",
    "    for i in range(N_rz):\n",
    "        if (i+1) % 1000 == 0:\n",
    "            msg = 'The %s th to %s th noise realizations are now being generated.' %(i+1, i+1000)\n",
    "            print(msg)\n",
    "        data[i], _ = noisegenerator(Tobs, Det, Sr, df, dt)\n",
    "        \n",
    "    for i in range(multiplication):\n",
    "        for j in range(len(SNewaves)):\n",
    "            \n",
    "            count = i * len(SNewaves) + j\n",
    "            if (count + 1) % 1000 == 0 and count < 4999:\n",
    "                msg = 'The %s th to %s th samples of the data set are now being generated.' %(count + 1,count + 1000)\n",
    "                print(msg)\n",
    "            data[count] += SNewaves[j]\n",
    "            \n",
    "            fftinput_1 = pyfftw.empty_aligned(len(data[count]), dtype='complex128')\n",
    "            fft_object_1 = pyfftw.builders.rfft(fftinput_1)\n",
    "            temporary = fft_object_1(data[count]) * 1.0/New_sr\n",
    "            temporary = temporary / ASD \n",
    "        \n",
    "        \n",
    "            SNR[count] = np.sqrt(4.0 * sum(abs(temporary[int(100.0/df) : int(500.0/df)]) ** 2 * df))\n",
    "        \n",
    "            fftinput_2 = pyfftw.empty_aligned(len(temporary), dtype='complex128')\n",
    "            fft_object_2 = pyfftw.builders.irfft(fftinput_2)\n",
    "            data[count] = fft_object_2(temporary) * df\n",
    "    \n",
    "            \n",
    "    return data, SNR\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[2500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1000 th to 1999 th noise realizations are now being generated.\n",
      "The 2000 th to 2999 th noise realizations are now being generated.\n",
      "The 3000 th to 3999 th noise realizations are now being generated.\n",
      "The 4000 th to 4999 th noise realizations are now being generated.\n",
      "The 5000 th to 5999 th noise realizations are now being generated.\n",
      "The 1000 th to 1999 th samples of the data set are now being generated.\n",
      "The 2000 th to 2999 th samples of the data set are now being generated.\n"
     ]
    }
   ],
   "source": [
    "dt = 1.0/New_sr\n",
    "multiplication = 25\n",
    "seed = 10\n",
    "Det = 'H1'\n",
    "N_rz = 5000#- len(SNewaves)  * multiplication\n",
    "data, SNR = data_generator(seed, ts, New_sr, Det, SNewaves, N_rz, multiplication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(data[59]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1200)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_start_index_signal, train_end_index_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 3700)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_start_index_noise, train_end_index_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 2400)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_start_index_signal, val_end_index_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 4900)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_start_index_noise, val_end_index_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 5000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_start_index_signal, test_end_index_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_for_test = 100\n",
    "nos_portion = (len(data) - multiplication * len(SNewaves) - save_for_test)/2\n",
    "\n",
    "\n",
    "nos_start = multiplication * len(SNewaves)\n",
    "\n",
    "train_start_index_signal = 0\n",
    "train_end_index_signal = (multiplication * len(SNewaves) - save_for_test) / 2\n",
    "\n",
    "train_start_index_noise = nos_start\n",
    "train_end_index_noise = nos_start + nos_portion\n",
    "\n",
    "\n",
    "val_start_index_signal = train_end_index_signal\n",
    "val_end_index_signal = multiplication * len(SNewaves) - save_for_test\n",
    "\n",
    "val_start_index_noise = train_end_index_noise\n",
    "val_end_index_noise = train_end_index_noise + nos_portion\n",
    "\n",
    "\n",
    "test_start_index_signal = val_end_index_signal\n",
    "test_end_index_signal =  val_end_index_signal + save_for_test\n",
    "\n",
    "test_start_index_noise = val_end_index_noise\n",
    "test_end_index_noise =  val_end_index_noise + save_for_test\n",
    "\n",
    "\n",
    "train_signal = np.concatenate((data[train_start_index_signal:train_end_index_signal], \n",
    "                               data[train_start_index_noise:train_end_index_noise]))\n",
    "\n",
    "train_label = np.concatenate((np.ones(train_end_index_signal - train_start_index_signal), \n",
    "                              np.zeros(train_end_index_noise - train_start_index_noise)))\n",
    "\n",
    "val_signal = np.concatenate((data[val_start_index_signal:val_end_index_signal], \n",
    "                            data[val_start_index_noise:val_end_index_noise]))\n",
    "\n",
    "val_label = np.concatenate((np.ones(val_end_index_signal - val_start_index_signal), \n",
    "                            np.zeros(val_end_index_noise - val_start_index_noise)))\n",
    "\n",
    "\n",
    "test_signal = np.concatenate((data[test_start_index_signal : test_end_index_signal], \n",
    "                             data[test_start_index_noise : test_end_index_noise]))\n",
    "\n",
    "test_label = np.concatenate((np.ones(test_end_index_signal - test_start_index_signal), \n",
    "                            np.zeros(test_end_index_noise - test_start_index_noise)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "plt.plot(train_signal[0])\n",
    "print(train_label[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n"
     ]
    }
   ],
   "source": [
    "sanity(train_signal, train_label)\n",
    "#sanity(test_signal, test_label)\n",
    "#sanity(val_signal, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity(signal, label):\n",
    "    for i, test_signal in enumerate(signal):\n",
    "        if np.array_equal(test_signal, np.zeros_like(test_signal)) == True and label[i] != 0:\n",
    "            print(i)\n",
    "        elif np.array_equal(test_signal, np.zeros_like(test_signal)) == False and label[i] != 1:\n",
    "            print(i)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathandname = \"./Data/simulatedwave_plus_noise_first_100_fft.pkl\"\n",
    "fp = open(pathandname,\"w\")\n",
    "pickle.dump([train_signal, train_label, val_signal, val_label, test_signal, test_label], fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/simulatedwave_plus_noise_first_100_fft.pkl') as f:\n",
    "    train_signal, train_label, val_signal, val_label, test_signal, test_label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signal = train_signal * 1e7\n",
    "val_signal = val_signal * 1e7\n",
    "test_signal = test_signal * 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1#1834\n",
    "y = 1784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "plt.plot(train_signal[i])\n",
    "#plt.plot(SNewaves[y])\n",
    "print(train_label[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test = np.fft.rfft(train_signal[i]) * dt\n",
    "Ns = len(data[i])\n",
    "Nf = int(np.ceil(Ns /2) + 1)\n",
    "fs = np.arange(Nf) * df\n",
    "ASD = readnos('H1', fs)\n",
    "test = test / ASD \n",
    "test = np.fft.irfft(test) * df\n",
    "plt.plot(test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009027880081392462"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(train_signal, train_label, val_signal, val_label, test_signal, test_label,  shuffle_times):\n",
    "    \n",
    "    for i in range(shuffle_times):\n",
    "        state = np.random.randint(0,100)\n",
    "        train_signal, train_label = shuffle(train_signal, train_label, random_state=state)\n",
    "\n",
    "        state = np.random.randint(0,100)\n",
    "        test_signal, test_label = shuffle(test_signal, test_label, random_state=state)\n",
    "\n",
    "        state = np.random.randint(0,100)\n",
    "        val_signal, val_label = shuffle(val_signal, val_label, random_state=state)\n",
    "\n",
    "    return train_signal, train_label, val_signal, val_label, test_signal, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signal, train_label, val_signal, val_label, test_signal, test_label = shuffle_data(train_signal, train_label, val_signal, val_label, test_signal, test_label,  4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "i = 14\n",
    "#plt.plot(ts, train_signal[i])\n",
    "plt.plot(ts, val_signal[i])\n",
    "#print(train_label[i])\n",
    "print(val_label[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Below is the CNN part of this code\"\"\" \n",
    "\n",
    "batch_size = 30      # number of time series per batch\n",
    "num_classes = 2      # signal or background\n",
    "epochs = 20          # number of full passes of the dataset\n",
    "outdir = './results' # directory to store results in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(train_signal)\n",
    "signal_len = len(train_signal[0])\n",
    "\n",
    "train_signal = train_signal.reshape(length,1, signal_len)\n",
    "test_signal = test_signal.reshape(len(test_signal),1, signal_len)\n",
    "val_signal = val_signal.reshape(length,1, signal_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_first')\n",
    "signal_len = len(train_signal[0][0])\n",
    "\n",
    "train_signal = train_signal.reshape(-1, 1, 1, signal_len)\n",
    "val_signal = val_signal.reshape(-1, 1, 1, signal_len)\n",
    "test_signal = test_signal.reshape(-1, 1, 1, signal_len)\n",
    "\n",
    "input_shape = train_signal.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = keras.utils.to_categorical(train_label , num_classes)\n",
    "val_label = keras.utils.to_categorical(val_label, num_classes)\n",
    "test_label = keras.utils.to_categorical(test_label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-431e0f531433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# add the layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# conv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# maxpool2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()    # define the type of keras model\n",
    "\n",
    "# add the layers\n",
    "# conv1\n",
    "model.add(Conv2D(16, (1,64), activation='elu', input_shape=input_shape))\n",
    "# maxpool2\n",
    "model.add(MaxPool2D((1,4)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(16, (1,16), activation='elu'))\n",
    "# maxpool2\n",
    "model.add(MaxPool2D((1,4)))\n",
    "\n",
    "\n",
    "# the input the fully connected layer must be 1-D vector\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "# add the output layer with softmax actiavtion for classication\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# print a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 8, 1, 13501)       520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 1, 1687)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 1, 1672)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 1, 278)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4448)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                142368    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 145,018\n",
      "Trainable params: 145,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()    # define the type of keras model\n",
    "\n",
    "# add the layers\n",
    "# conv1\n",
    "model.add(Conv2D(8, (1,64), activation='elu', input_shape=input_shape))\n",
    "# maxpool2\n",
    "model.add(MaxPool2D((1,8)))\n",
    "# conv2\n",
    "model.add(Conv2D(16, (1,16), activation='elu'))\n",
    "# maxpool2\n",
    "model.add(MaxPool2D((1,6)))\n",
    "# the input the fully connected layer must be 1-D vector\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "# add the output layer with softmax actiavtion for classication\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# print a summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr = 0.1),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelCheck = ModelCheckpoint('{0}/best_weights.hdf5'.format(outdir), monitor='val_acc', verbose=0, \n",
    "                save_best_only=True,save_weights_only=True, mode='auto', period=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 2400 samples\n",
      "Epoch 1/20\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 6.6408 - acc: 0.5058 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "2400/2400 [==============================] - 2s 874us/step - loss: 7.8760 - acc: 0.4967 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "2400/2400 [==============================] - 2s 899us/step - loss: 7.8902 - acc: 0.4979 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "2400/2400 [==============================] - 2s 884us/step - loss: 7.8741 - acc: 0.4992 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "2400/2400 [==============================] - 2s 881us/step - loss: 7.8724 - acc: 0.4975 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "2400/2400 [==============================] - 2s 882us/step - loss: 7.8493 - acc: 0.4967 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "2400/2400 [==============================] - 2s 865us/step - loss: 7.8298 - acc: 0.4988 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "2400/2400 [==============================] - 2s 894us/step - loss: 7.8002 - acc: 0.5033 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "2400/2400 [==============================] - 2s 834us/step - loss: 7.7595 - acc: 0.5029 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "2400/2400 [==============================] - 2s 839us/step - loss: 7.8703 - acc: 0.4958 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/20\n",
      "2400/2400 [==============================] - 2s 869us/step - loss: 7.7586 - acc: 0.5025 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/20\n",
      "2400/2400 [==============================] - 2s 885us/step - loss: 7.8617 - acc: 0.4983 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "2400/2400 [==============================] - 2s 849us/step - loss: 7.8849 - acc: 0.4979 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "2400/2400 [==============================] - 2s 916us/step - loss: 7.7504 - acc: 0.5013 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "2400/2400 [==============================] - 2s 899us/step - loss: 7.8055 - acc: 0.5050 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "2400/2400 [==============================] - 2s 869us/step - loss: 7.8577 - acc: 0.5004 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "2400/2400 [==============================] - 2s 851us/step - loss: 7.8081 - acc: 0.4996 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "2400/2400 [==============================] - 2s 831us/step - loss: 7.8404 - acc: 0.4979 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "2400/2400 [==============================] - 2s 836us/step - loss: 7.8402 - acc: 0.4996 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "2400/2400 [==============================] - 2s 850us/step - loss: 7.8374 - acc: 0.5021 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_signal, train_label,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_signal, val_label),\n",
    "                    callbacks = [modelCheck]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 365us/step\n",
      "('Test loss:', 1.1920930376163597e-07)\n",
      "('Test accuracy:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# load the best model\n",
    "model.load_weights('{0}/best_weights.hdf5'.format(outdir))\n",
    "# evaluate\n",
    "eval_results = model.evaluate(test_signal, test_label,\n",
    "                              sample_weight=None,\n",
    "                              batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', eval_results[0])\n",
    "print('Test accuracy:', eval_results[1])\n",
    "signal_preds = model.predict(test_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "signal_preds = model.predict(test_signal)\n",
    "print(signal_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axs = plt.subplots(2,1, sharex = True)\n",
    "axs = axs.ravel()\n",
    "# plot history\n",
    "axs[0].plot(history.history['loss'], label = 'loss')\n",
    "axs[0].plot(history.history['val_loss'], label = 'val loss')\n",
    "axs[1].plot(history.history['acc'], label = 'acc')\n",
    "axs[1].plot(history.history['val_acc'], label = 'val_acc')\n",
    "# set labels\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Acc')\n",
    "# legends\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "# grids\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
